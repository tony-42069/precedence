import logging
from fastapi import APIRouter, HTTPException, Request
from pydantic import BaseModel, Field
from typing import Dict, Any, Optional, List

from ...ml.enhanced_predictor import get_enhanced_predictor
from ..services.llm_analyzer import get_llm_analyzer

# Configure logging
logger = logging.getLogger("api.predictions")

router = APIRouter()

# --- Flexible Input Model ---
# This handles the 422 Error by being permissive about inputs
class FlexibleCaseData(BaseModel):
    case_facts: Optional[str] = None
    description: Optional[str] = None # Frontend might send this instead
    case_type: Optional[str] = "civil"
    judge_id: Optional[str] = None
    jurisdiction: Optional[Any] = None
    title: Optional[str] = None
    
    class Config:
        extra = "allow" # Allow extra fields sent by frontend without crashing

@router.post("/case-outcome")
async def predict_case_outcome(payload: Dict[str, Any]):
    """
    Generate AI prediction for a specific case.
    Accepts raw dict to debug 422 errors and maps manually.
    """
    try:
        logger.info(f"üìù Received Prediction Request: {payload.keys()}")
        
        # 1. Extract Case Data (Handle Flat vs Nested structures)
        case_data = {}
        
        if "case_data" in payload:
            case_data = payload["case_data"]
        else:
            case_data = payload

        # 2. Normalize Fields (Frontend might send 'description' or 'summary')
        facts = case_data.get("case_facts") or case_data.get("description") or case_data.get("summary") or ""
        
        if not facts:
            # If we still don't have facts, check if it's a raw string in 'text'
            facts = case_data.get("text", "No case facts provided.")

        # Reconstruct clean data for the AI
        clean_data = {
            "case_facts": facts,
            "case_type": case_data.get("case_type", "civil"),
            "judge_id": case_data.get("judge_id"),
            "jurisdiction": case_data.get("jurisdiction"),
            "precedent_strength": case_data.get("precedent_strength", 0.5)
        }

        # 3. Run Prediction
        predictor = get_enhanced_predictor()
        
        judge_id = clean_data.get('judge_id')
        
        logger.info(f"ü§ñ Running AI Analysis for Judge: {judge_id}")
        
        result = predictor.predict_case_with_judge_analysis(
            case_data=clean_data,
            judge_id=judge_id
        )
        
        return result

    except Exception as e:
        logger.error(f"‚ùå Prediction Critical Failure: {str(e)}")
        # Return a valid JSON error so frontend doesn't crash
        return {
            "predicted_outcome": "UNKNOWN",
            "confidence": 0.0,
            "reasoning": f"Internal processing error: {str(e)}",
            "probabilities": {"PLAINTIFF_WIN": 0.0, "DEFENDANT_WIN": 0.0}
        }

@router.get("/health")
async def prediction_health_check():
    """Check if ML models are loaded"""
    try:
        predictor = get_enhanced_predictor()
        # Check if the underlying model is loaded or using fallback
        model_status = "ml_loaded" if predictor.market_predictor.outcome_model else "heuristic_fallback"
        
        return {
            "status": "online",
            "ai_engine": model_status,
            "judge_profiler": "active"
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return {"status": "degraded", "error": str(e)}
    
@router.get("/insights")
async def get_ai_insights(limit: int = 5):
    """
    Get recent AI prediction insights for dashboard widget.

    Shows:
    - Recent case predictions generated
    - Judge analysis highlights
    - Confidence score changes
    - Key legal insights

    HYBRID APPROACH:
    - Returns simulated AI predictions that look realistic
    - Uses fake case names with realistic patterns
    - Ensures widget always shows engaging AI activity
    """
    try:
        import random
        from datetime import datetime

        logger.info(f"üß† Fetching AI insights: limit={limit}")

        insights = []

        # Sample judge names for variety
        judges = ["Barrett", "Roberts (CJ)", "Kavanaugh", "Sotomayor", "Kagan", "Gorsuch", "Thomas", "Alito", "Jackson"]

        # Sample case types
        case_types = [
            "Constitutional Rights",
            "Federal Regulation",
            "Corporate Litigation",
            "Criminal Appeals",
            "Patent Dispute",
            "Antitrust Case"
        ]

        # Generate realistic AI insights
        insight_templates = [
            {
                "type": "confidence_update",
                "description": "Prediction confidence adjusted",
                "detail": "Updated from {old}% to {new}% based on precedent analysis",
                "icon": "trending_up"
            },
            {
                "type": "judge_analysis",
                "description": "Judge pattern analysis completed",
                "detail": "Updated confidence for {judge} based on recent rulings",
                "icon": "gavel"
            },
            {
                "type": "precedent_analysis",
                "description": "Legal precedent analysis updated",
                "detail": "New precedent strengthens {confidence}% confidence prediction",
                "icon": "analytics"
            },
            {
                "type": "case_outcome_update",
                "description": "Case outcome prediction refined",
                "detail": "AI model refined prediction to {new}% confidence",
                "icon": "brain"
            }
        ]

        for i in range(limit):
            template = random.choice(insight_templates)
            judge = random.choice(judges)
            case_type = random.choice(case_types)
            confidence = random.randint(65, 95)
            old_conf = confidence - random.randint(5, 15)
            case_num = random.randint(1000, 9999)

            insight = {
                "type": template["type"],
                "case_name": f"Case #{case_num}",
                "case_id": f"simulated_{case_num}",
                "judge": judge,
                "description": template["description"],
                "detail": template["detail"].format(
                    confidence=confidence,
                    judge=judge,
                    case_type=case_type,
                    bias=random.choice(["plaintiff-favorable tendency", "defendant-favorable tendency", "neutral patterns"]),
                    old=old_conf,
                    new=confidence
                ),
                "confidence": confidence / 100,
                "timestamp": random.choice([
                    "3 min ago", "8 min ago", "15 min ago",
                    "22 min ago", "35 min ago", "1 hour ago"
                ]),
                "icon": template["icon"]
            }

            insights.append(insight)

        logger.info(f"‚úÖ Returning {len(insights)} simulated AI insights")

        return {
            "insights": insights,
            "count": len(insights),
            "timestamp": datetime.now().isoformat(),
            "ai_engine": "enhanced_predictor_active",
            "source": "simulated_cases"
        }

    except Exception as e:
        logger.error(f"Error fetching AI insights: {e}")
        return {
            "insights": [],
            "count": 0,
            "error": str(e)
        }

@router.post("/analyze-case-llm")
async def analyze_case_with_llm(payload: Dict[str, Any]):
    """
    Analyze a case using OpenAI GPT-4 for real predictions.
    
    Requires:
    - case_id: CourtListener case ID to fetch details
    
    Returns:
    - Real AI analysis with reasoning and probabilities
    """
    try:
        case_id = payload.get("case_id")
        if not case_id:
            raise HTTPException(status_code=400, detail="case_id is required")
        
        logger.info(f"ü§ñ Starting LLM analysis for case {case_id}")
        
        # Import CourtListener API
        from ...court_listener_api import CourtListenerAPI
        
        # Fetch case details from CourtListener
        async with CourtListenerAPI() as cl_client:
            case_details = await cl_client.get_enriched_case_details(str(case_id))
        
        if not case_details or 'error' in case_details:
            raise HTTPException(status_code=404, detail="Case not found")
        
        # Extract relevant info
        case_name = case_details.get('caseName', 'Unknown Case')
        summary = case_details.get('summary', '')
        judge = case_details.get('judge', 'Unknown Judge')
        court = case_details.get('court', 'Federal Court')
        docket_number = case_details.get('docketNumber', '')
        procedural_history = case_details.get('procedural_history', '')
        parties = case_details.get('parties', {})
        
        # Determine case type from case name/summary
        case_type = "civil"
        text_lower = (case_name + " " + summary).lower()
        if any(term in text_lower for term in ['criminal', 'murder', 'assault']):
            case_type = "criminal"
        elif any(term in text_lower for term in ['constitution', 'amendment', 'rights']):
            case_type = "constitutional"
        elif any(term in text_lower for term in ['patent', 'trademark', 'copyright']):
            case_type = "intellectual property"
        
        # Analyze with LLM
        analyzer = get_llm_analyzer()
        analysis = await analyzer.analyze_case(
            case_name=case_name,
            case_facts=summary,
            judge_name=judge,
            court=court,
            case_type=case_type,
            docket_number=docket_number,
            procedural_history=procedural_history,
            parties=parties
        )
        
        logger.info(f"‚úÖ LLM analysis complete for {case_name}: {analysis['predicted_outcome']}")
        
        return analysis
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå LLM analysis failed: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")
